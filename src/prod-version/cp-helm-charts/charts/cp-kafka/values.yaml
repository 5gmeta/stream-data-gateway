# Default values for cp-kafka.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

## ------------------------------------------------------
## Kafka
## ------------------------------------------------------

## Number of Kafka brokers
brokers: 3

## Image Info
## ref: https://hub.docker.com/r/confluentinc/cp-server/
image: confluentinc/cp-kafka
imageTag: 7.5.1

## Specify a imagePullPolicy
## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
imagePullPolicy: IfNotPresent

## Specify an array of imagePullSecrets.
## Secrets must be manually created in the namespace.
## ref: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
imagePullSecrets:

## StatefulSet Config
## Start and stop pods in Parallel or OrderedReady (one-by-one.)
## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy
podManagementPolicy: OrderedReady

## The StatefulSet Update Strategy which Kafka will use when changes are applied: OnDelete or RollingUpdate
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
updateStrategy: RollingUpdate


# Security Context
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
# for Kafka container
securityContext: {}
  #  runAsUser: 1000
  #  runAsGroup: 1000

## Kafka Server properties
## ref: https://kafka.apache.org/documentation/#configuration
configurationOverrides:
  "offsets.topic.replication.factor": "3"
  # "default.replication.factor": 3
  # "min.insync.replicas": 2
  # "auto.create.topics.enable": false
  ######## 5GMETA ############
#  "log.retention.hours": "" # Default: 168
#  "log.retention.minutes": "1" # Default: null
  "log.retention.ms": "40000" # Default: null
#  "log.retention.bytes": "" # Default: -1
#  "log.cleaner.delete.retention.ms": "" # Default: 86400000 (1 day)
  "log.retention.check.interval.ms": "60000" # Default: 300000 (5 minutes)
#  "retention.ms": "" # Default: 604800000 (7 days)
#  "retention.bytes": "" # Default: -1
#  "delete.retention.ms": "" # Default: 86400000 (1 day)
  ## Options required for external access via NodePort
  ## ref:
  ## - http://kafka.apache.org/documentation/#security_configbroker
  ## - https://cwiki.apache.org/confluence/display/KAFKA/KIP-103%3A+Separation+of+Internal+and+External+traffic
  ##
  ## Advertised listeners will use the firstListenerPort value as it's default unless overridden here.
  ## Setting "advertised.listeners" here appends to "PLAINTEXT://${POD_IP}:9092,"
#   EXTERNAL://${HOST_IP}:$((31090 + ${KAFKA_BROKER_ID}))
#   EXTERNAL://13.39.20.247:$((31090 + ${KAFKA_BROKER_ID}))
  "advertised.listeners": |-
   REPLICATION://${POD_IP}:$((31090 + ${KAFKA_BROKER_ID}))
  "listener.security.protocol.map": |-
   REPLICATION:SASL_SSL,CLIENT:SASL_SSL

## Additional env variables
customEnv:
  # KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
  # CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "localhost:9092"
  KAFKA_MESSAGE_MAX_BYTES: "15000000"
  KAFKA_MAX_MESSAGE_BYTES: "15000000"

extraDeploy:
  - |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: kafka-ui
      labels:
        app.kubernetes.io/component: kafka-ui
      namespace: kafka
    spec:
      replicas: 1
      selector:
        matchLabels:
          app.kubernetes.io/component: kafka-ui
      template:
        metadata:
          labels:
            app.kubernetes.io/component: kafka-ui
        spec:
          volumes:
          - name: volume-ssl
            persistentVolumeClaim:
              claimName: pvc-ssl
          - name: jar-for-kafka
            hostPath:
              path: "/home/meta/jar-for-kafka/"
          containers:
          - name: kafka-ui
            image: provectuslabs/kafka-ui:0.3.3
            imagePullPolicy: Always
            command:
              - sh
              - -exc
              - |
                mkdir /usr/share/java/cp-base-new -p
                cp /app/* /usr/share/java/cp-base-new
                java --add-opens java.rmi/javax.rmi.ssl=ALL-UNNAMED -cp /kafka-ui-api.jar -Dloader.path=/usr/share/java/cp-base-new/ org.springframework.boot.loader.PropertiesLauncher
            ports:
              - name: http
                containerPort: 8443
                protocol: TCP
            volumeMounts:
            - name: volume-ssl
              mountPath: "/etc/ssl/certs/docker/"
            - name: jar-for-kafka
              mountPath: "/app/"
            env:
              - name: KAFKA_CLUSTERS_0_NAME
                value: 5gmeta-cloud
              - name: KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS
                value: kafkacluster-cp-kafka.kafka.svc.cluster.local:9092
    #          - name: KAFKA_CLUSTERS_0_ZOOKEEPER
    #            value: kafkacluster-cp-zookeeper.kafka.svc.cluster.local:2181
              - name: KAFKA_CLUSTERS_0_SCHEMAREGISTRY
                value: http://kafkacluster-cp-schema-registry.kafka.svc.cluster.local:8081
              - name: KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME
                value: kafka-connect
              - name: KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS
                value: http://kafkacluster-cp-kafka-connect.kafka.svc.cluster.local:8083
              - name: KAFKA_CLUSTERS_0_KSQLDBSERVER
                value: http://kafka-cp-ksql-server.kafka.svc.cluster.local:8088
              - name: JAVA_OPTS
                value: "java --add-opens java.rmi/javax.rmi.ssl=ALL-UNNAMED -cp /kafka-ui-api.jar -Dloader.path=/usr/share/java/cp-base-new/ org.springframework.boot.loader.PropertiesLauncher"
              - name: AUTH_TYPE
                value: "LOGIN_FORM"
              - name: SPRING_SECURITY_USER_NAME
                value: admin
              - name: SPRING_SECURITY_USER_PASSWORD
                value: admin
              - name: SERVER_PORT
                value: "8443"
              - name: SERVER_SSL_KEY-STORE
                value: /etc/ssl/certs/docker/kafka-ui1.jks
              - name: SERVER_SSL_KEY-STORE-PASSWORD
                value: dockerpw
              - name: SERVER_SSL_KEY-PASSWORD
                value: dockerpw
              - name: KAFKA_CLUSTERS_0_PROPERTIES_SSL_KEYSTORE_LOCATION
                value: /etc/ssl/certs/docker/broker1.jks
              - name: KAFKA_CLUSTERS_0_PROPERTIES_SSL_KEYSTORE_PASSWORD
                value: dockerpw
              - name: KAFKA_CLUSTERS_0_PROPERTIES_SSL_KEY_PASSWORD
                value: dockerpw
              - name: KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION
                value: /etc/ssl/certs/docker/truststore.jks
              - name: KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_PASSWORD
                value: dockerpw
              - name: KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL
                value: SASL_SSL
              - name: KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM
                valuo: OAUTHBEARER
              - name: KAFKA_CLUSTERS_0_PROPERTIES_SASL_LOGIN_CALLBACK_HANDLER_CLASS
                value: io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler
      #KAFKA_CLUSTERS_0_PROPERTIES_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler
              - name: KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG
                value: >
                        org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required
                        oauth.username.claim="preferred_username"
                        unsecuredLoginStringClaim_sub="unused"
                        oauth.client.id="kafka"
                        oauth.client.secret="74VDKrusp8aTkD3cFVlIYS3soz7AIeYA"
                        oauth.token.endpoint.uri="https://keycloak:8443/realms/demo/protocol/openid-connect/token";
                        oauth.ssl.truststore.location="/etc/ssl/certs/docker/truststore.jks"
                        oauth.ssl.truststore.password="dockerpw"

  - |
    apiVersion: v1
    kind: Service
    metadata:
      name: kafka-ui
      labels:
        app.kubernetes.io/component: kafka-ui
      namespace: kafka
    spec:
      type: NodePort
      ports:
        - port: 8443
          protocol: TCP
          targetPort: http
          nodePort: 31080
      selector:
        app.kubernetes.io/component: kafka-ui
  - |
    apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      labels:
        release: prometheus-stack
      name: kafkacluster
      namespace: monitoring
    spec:
      endpoints:
      - interval: 30s
        port: metrics
      namespaceSelector:
        matchNames:
        - kafka
      selector:
        matchLabels:
          release: kafkacluster

persistence:
  enabled: true
  
  existingClaim: ""

  ## The size of the PersistentVolume to allocate to each Kafka Pod in the StatefulSet. For
  ## production servers this number should likely be much larger.
  size: 1Gi

  ## Kafka data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: ""

  disksPerBroker: 1

## Kafka JVM Heap Option
heapOptions: "-Xms512M -Xmx512M"

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

## Custom pod annotations
podAnnotations: {}

## Node labels for pod assignment
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
nodeSelector: {}

## Taints to tolerate on node assignment:
## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
tolerations: []

## Pod scheduling constraints
## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity
affinity: {}

## Monitoring
## Kafka JMX Settings
## ref: https://docs.confluent.io/current/kafka/monitoring.html
jmx:
  port: 5555

## Prometheus Exporter Configuration
## ref: https://prometheus.io/docs/instrumenting/exporters/
prometheus:
  ## JMX Exporter Configuration
  ## ref: https://github.com/prometheus/jmx_exporter
  jmx:
    enabled: true
    image: solsson/kafka-prometheus-jmx-exporter@sha256
    imageTag: 6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143
    imagePullPolicy: IfNotPresent
    port: 5556

    ## Resources configuration for the JMX exporter container.
    ## See the `resources` documentation above for details.
    resources: {}

nodeport:
  enabled: true
  servicePort: 19092
  firstListenerPort: 31090

## ------------------------------------------------------
## Zookeeper
## ------------------------------------------------------
cp-zookeeper:
  ## If true, install the cp-zookeeper chart alongside cp-kafka
  ## ref: ../cp-zookeeper
  enabled: true
  servers: 3
  persistence:
    enabled: true
    dataDirSize: 5Gi
    dataLogDirSize: 5Gi

  ## If the Zookeeper Chart is disabled a URL and port are required to connect
  url: ""
